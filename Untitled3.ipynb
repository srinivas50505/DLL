{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f33310b-459c-4ac3-8315-5f10be525813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traing_img (60000, 28, 28)\n",
      "test_img (10000, 28, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SRINIVAS\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.8844 - loss: 0.4258\n",
      "Epoch 2/2\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.9730 - loss: 0.0870\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.9682 - loss: 0.1021\n",
      "Test Loss 0.10205451399087906\n",
      "Test Accuracy 0.9682000279426575\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "objects=mnist\n",
    "(train_img,train_lab),(test_img,test_lab)=objects.load_data()\n",
    "print(\"traing_img\",train_img.shape)\n",
    "print(\"test_img\",test_img.shape)\n",
    "train_img=train_img/255\n",
    "test_img=test_img/255\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten,Dense\n",
    "model=Sequential()\n",
    "input_layer=Flatten(input_shape=(28,28))\n",
    "model.add(input_layer)\n",
    "hidden_layer1=Dense(512,activation=\"relu\")\n",
    "model.add(hidden_layer1)\n",
    "hidden_layer2=Dense(512,activation=\"relu\")\n",
    "model.add(hidden_layer2)\n",
    "output_layer=Dense(512,activation=\"softmax\")\n",
    "model.add(output_layer)\n",
    "model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\"\n",
    "             ,metrics=[\"accuracy\"])\n",
    "model.fit(train_img,train_lab,epochs=2)\n",
    "loss_and_acc=model.evaluate(test_img,test_lab,verbose=2)\n",
    "print(\"Test Loss\",loss_and_acc[0])\n",
    "print(\"Test Accuracy\",loss_and_acc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1061d89b-186c-41c6-be16-41db2a159c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.6163 - loss: 0.6156 - val_accuracy: 0.8088 - val_loss: 0.4092\n",
      "Epoch 2/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8514 - loss: 0.3366 - val_accuracy: 0.8441 - val_loss: 0.3498\n",
      "Epoch 3/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9140 - loss: 0.2260 - val_accuracy: 0.8227 - val_loss: 0.4291\n",
      "Epoch 4/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9609 - loss: 0.1289 - val_accuracy: 0.8203 - val_loss: 0.4689\n",
      "Epoch 5/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9849 - loss: 0.0631 - val_accuracy: 0.8180 - val_loss: 0.5663\n",
      "Epoch 6/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9938 - loss: 0.0307 - val_accuracy: 0.8162 - val_loss: 0.6628\n",
      "Epoch 7/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9978 - loss: 0.0151 - val_accuracy: 0.8165 - val_loss: 0.7455\n",
      "Epoch 8/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9996 - loss: 0.0063 - val_accuracy: 0.8176 - val_loss: 0.7965\n",
      "Epoch 9/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9998 - loss: 0.0032 - val_accuracy: 0.8160 - val_loss: 0.8482\n",
      "Epoch 10/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9999 - loss: 0.0019 - val_accuracy: 0.8174 - val_loss: 0.8814\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8168 - loss: 0.8904\n",
      "Test Accuracy :  81.73999786376953\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Embedding,Flatten\n",
    "num_words=1000\n",
    "max_length=200\n",
    "(x_train,y_train),(x_test,y_test)=imdb.load_data(num_words=1000)\n",
    "x_train=tf.keras.preprocessing.sequence.pad_sequences(x_train,maxlen=max_length)\n",
    "x_test=tf.keras.preprocessing.sequence.pad_sequences(x_test,maxlen=max_length)\n",
    "model =Sequential()\n",
    "model.add(Embedding(input_dim=num_words,output_dim=32))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.fit(x_train,y_train,epochs=10,batch_size=128,validation_data=(x_test,y_test))\n",
    "loss,accuracy=model.evaluate(x_test,y_test)\n",
    "print(\"Test Accuracy : \",accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3951e585-a9ba-44e6-9151-1fc37d8d82b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.1572 - loss: 3.6425 - val_accuracy: 0.4569 - val_loss: 2.7900\n",
      "Epoch 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4111 - loss: 2.7120 - val_accuracy: 0.6032 - val_loss: 1.9012\n",
      "Epoch 3/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5175 - loss: 2.0824 - val_accuracy: 0.6522 - val_loss: 1.6064\n",
      "Epoch 4/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5773 - loss: 1.7552 - val_accuracy: 0.6839 - val_loss: 1.4399\n",
      "Epoch 5/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6285 - loss: 1.5548 - val_accuracy: 0.6962 - val_loss: 1.3361\n",
      "Epoch 6/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6582 - loss: 1.4149 - val_accuracy: 0.7040 - val_loss: 1.2744\n",
      "Epoch 7/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6747 - loss: 1.3529 - val_accuracy: 0.7145 - val_loss: 1.2289\n",
      "Epoch 8/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6941 - loss: 1.2527 - val_accuracy: 0.7179 - val_loss: 1.1923\n",
      "Epoch 9/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7049 - loss: 1.1972 - val_accuracy: 0.7301 - val_loss: 1.1638\n",
      "Epoch 10/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7190 - loss: 1.1314 - val_accuracy: 0.7340 - val_loss: 1.1382\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7393 - loss: 1.1621\n",
      "test Accuracy:  72.61798977851868\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "(x_train,y_train),(x_test,y_test)=reuters.load_data(num_words=10000)\n",
    "def Vectorize_Sequences(sequences,dimension=10000):\n",
    "    results=np.zeros((len(sequences),dimension))\n",
    "    for i ,sequence in enumerate(sequences):\n",
    "        results[i,sequence]=1\n",
    "    return results\n",
    "x_train=Vectorize_Sequences(x_train)\n",
    "x_test=Vectorize_Sequences(x_test)\n",
    "num_classes=np.max(y_train)+1\n",
    "y_train=to_categorical(y_train,num_classes)\n",
    "y_test=to_categorical(y_test,num_classes)\n",
    "model=Sequential([\n",
    "                 Input(shape=(10000,)),\n",
    "                 Dense(64,activation=\"relu\"),\n",
    "                 Dropout(0.5),\n",
    "                 Dense(64,activation=\"relu\"),\n",
    "                 Dropout(0.5),\n",
    "                 Dense(num_classes,activation=\"softmax\")])\n",
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "history=model.fit(x_train,y_train,epochs=10,batch_size=512,validation_split=0.2)\n",
    "loss,accuracy=model.evaluate(x_test,y_test)\n",
    "print(\"test Accuracy: \",accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3358f2e6-2c0d-43e6-bf90-fdf4a6383958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 511.4612 - val_loss: 477.1661\n",
      "Epoch 2/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 350.9897 - val_loss: 228.3052\n",
      "Epoch 3/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 148.7928 - val_loss: 76.2493\n",
      "Epoch 4/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.6261 - val_loss: 52.4875\n",
      "Epoch 5/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 82.7119 - val_loss: 37.1465\n",
      "Epoch 6/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.1813 - val_loss: 34.3265\n",
      "Epoch 7/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 53.4046 - val_loss: 28.3816\n",
      "Epoch 8/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 51.1691 - val_loss: 27.2215\n",
      "Epoch 9/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 46.4853 - val_loss: 23.0076\n",
      "Epoch 10/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 52.6426 - val_loss: 23.4170\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 21.8415 \n",
      "Test Loss:  24.309907913208008\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "scaler=StandardScaler()\n",
    "x_train=scaler.fit_transform(x_train)\n",
    "x_test=scaler.fit_transform(x_test)\n",
    "model=Sequential([\n",
    "    Input(shape=(x_train.shape[1],)),\n",
    "    Dense(64,activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(64,activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer=\"adam\",loss=\"mean_squared_error\")\n",
    "history=model.fit(x_train,y_train,epochs=10,batch_size=8,validation_split=0.2)\n",
    "loss=model.evaluate(x_test,y_test)\n",
    "print(\"Test Loss: \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d9be014-eec3-417d-a23b-7a0c01acdb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SRINIVAS\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.9128 - loss: 0.2838\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.9855 - loss: 0.0454\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.9918 - loss: 0.0253\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.9944 - loss: 0.0184\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9956 - loss: 0.0131\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9845 - loss: 0.0472\n",
      "Test accuracy: 0.9868000149726868\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "Predicted classes: [7 2 1 ... 4 5 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22c026e42d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.datasets import mnist \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D \n",
    "# Load the MNIST dataset and split it into train and test sets \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data() \n",
    "# Reshape the input data to be 4-dimensional (batch_size, height, width, channels) \n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1) \n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1) \n",
    "# Normalize the pixel values to be between 0 and 1 \n",
    "x_train = x_train / 255.0 \n",
    "x_test = x_test / 255.0 \n",
    "# Define the CNN architecture \n",
    "model = Sequential([Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)), \n",
    "MaxPooling2D((2, 2)),Conv2D(64, (3, 3), activation='relu'),MaxPooling2D((2, 2)),Flatten(), \n",
    "Dense(128, activation='relu'),Dense(10, activation='softmax') ]) \n",
    "# Compile the model \n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])   \n",
    "# Train the model on the training data \n",
    "model.fit(x_train, y_train, epochs=5) \n",
    "# Evaluate the model on the test data \n",
    "test_loss, test_acc = model.evaluate(x_test, y_test) \n",
    "print('Test accuracy:', test_acc) \n",
    "# Predict new data \n",
    "import numpy as np \n",
    "from PIL import Image \n",
    "# Load a sample image and preprocess it \n",
    "import matplotlib.pyplot as plt \n",
    "predictions = model.predict(x_test) \n",
    "predicted_classes = np.argmax(predictions, axis=1) \n",
    "print('Predicted classes:', predicted_classes) \n",
    "plt.matshow(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f4e0b57-40db-46b9-b936-f1b5d125d261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830ms/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3us/step\n",
      "1 : menu ( 0.97)\n",
      "2 : binder ( 0.02)\n",
      "3 : web_site ( 0.01)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input,decode_predictions\n",
    "\n",
    "model=VGG16(weights=\"imagenet\",include_top=True)\n",
    "img_path=r\"C:\\Users\\SRINIVAS\\Pictures\\Screenshots\\Screenshot 2024-08-30 101341.png\"\n",
    "img=image.load_img(img_path,target_size=(224,224))\n",
    "x=image.img_to_array(img)\n",
    "x=np.expand_dims(x,axis=0)\n",
    "x=preprocess_input(x)\n",
    "predictions=model.predict(x)\n",
    "decode_predictions=decode_predictions(predictions,top=3)[0]\n",
    "for i ,(imagenet_id,label,score) in enumerate (decode_predictions):\n",
    "    print(f\"{i+1} : {label} ({score : .2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0335a987-90e1-4b33-9f4b-a97ff1c9bf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:  welcome to dl lab\n",
      "dl : [1, 0, 0, 0]\n",
      "lab : [0, 1, 0, 0]\n",
      "to : [0, 0, 1, 0]\n",
      "welcome : [0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "text=\"welcome to dl lab\"\n",
    "words=text.split()\n",
    "vocabulary=sorted(set(words))\n",
    "onehotencoding=[]\n",
    "for word in vocabulary:\n",
    "    encoding =[0]*len(vocabulary)\n",
    "    index=list(vocabulary).index(word)\n",
    "    encoding[index]=1\n",
    "    onehotencoding.append((word,encoding))\n",
    "print(\"Original text: \",text)\n",
    "for word,encoding in onehotencoding:\n",
    "    print(f\"{word} : {encoding}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ff73549-2dd6-4cd3-9f66-99dcd0c619e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Pad Sequences (Sample X time)\n",
      "Build Model.......\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SRINIVAS\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.6755 - loss: 0.5846 - val_accuracy: 0.8529 - val_loss: 0.3336\n",
      "Epoch 2/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9060 - loss: 0.2411 - val_accuracy: 0.8523 - val_loss: 0.3336\n",
      "Epoch 3/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9704 - loss: 0.1212 - val_accuracy: 0.8504 - val_loss: 0.3562\n",
      "Epoch 4/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9948 - loss: 0.0455 - val_accuracy: 0.8460 - val_loss: 0.3917\n",
      "Epoch 5/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0166 - val_accuracy: 0.8458 - val_loss: 0.4270\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.4329\n",
      "Test score:  0.42701154947280884\n",
      "Accuracy:  0.8458399772644043\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,Flatten,Dense\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_features=10000\n",
    "max_len=100\n",
    "batch_size=32\n",
    "epochs=5\n",
    "embedding_dim=50\n",
    "\n",
    "print(\"Loading data\")\n",
    "(x_train,y_train),(x_test,y_test)=imdb.load_data(num_words=max_features)\n",
    "print(\"Pad Sequences (Sample X time)\")\n",
    "x_train=pad_sequences(x_train,maxlen=max_len)\n",
    "x_test=pad_sequences(x_test,maxlen=max_len)\n",
    "print(\"Build Model.......\")\n",
    "model=Sequential()\n",
    "model.add(Embedding(max_features,embedding_dim,input_length=max_len))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,validation_data=(x_test,y_test))\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(\"Test score: \",score)\n",
    "print(\"Accuracy: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e92254a-1957-44d3-867d-8de223e6ab1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Pad Sequences (Sample X time)\n",
      "Build Model.......\n",
      "Epoch 1/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 105ms/step - accuracy: 0.7112 - loss: 0.5454 - val_accuracy: 0.8336 - val_loss: 0.3865\n",
      "Epoch 2/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 119ms/step - accuracy: 0.8709 - loss: 0.3157 - val_accuracy: 0.8428 - val_loss: 0.3748\n",
      "Epoch 3/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 121ms/step - accuracy: 0.9091 - loss: 0.2403 - val_accuracy: 0.8283 - val_loss: 0.4003\n",
      "Epoch 4/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 124ms/step - accuracy: 0.9301 - loss: 0.1817 - val_accuracy: 0.8432 - val_loss: 0.4364\n",
      "Epoch 5/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 106ms/step - accuracy: 0.9535 - loss: 0.1331 - val_accuracy: 0.8268 - val_loss: 0.5002\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.8233 - loss: 0.5119\n",
      "Test score:  0.5002380609512329\n",
      "Accuracy:  0.8267599940299988\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "max_features=20000\n",
    "max_len=100\n",
    "batch_size=32\n",
    "epochs=5\n",
    "\n",
    "print(\"Loading data\")\n",
    "(x_train,y_train),(x_test,y_test)=imdb.load_data(num_words=max_features)\n",
    "print(\"Pad Sequences (Sample X time)\")\n",
    "x_train=sequence.pad_sequences(x_train,maxlen=max_len)\n",
    "x_test=sequence.pad_sequences(x_test,maxlen=max_len)\n",
    "print(\"Build Model.......\")\n",
    "model=Sequential()\n",
    "model.add(Embedding(max_features,128))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2)) \n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,validation_data=(x_test,y_test))\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(\"Test score: \",score)\n",
    "print(\"Accuracy: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2436fce3-89a1-4e1f-875f-f1c69b145ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
